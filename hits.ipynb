{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "web_graph = nx.read_gpickle('web_graph.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# web_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# web_graph.nodes[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# pos = {i: web_graph.nodes[i]['pos'] for i in range(len(web_graph.nodes))}\n",
    "# nx.draw(web_graph, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Create a postings list\n",
    "# postings_list = {}\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# # print(stop_words)\n",
    "# for i in range(len(web_graph.nodes)):\n",
    "#     node = web_graph.nodes[i]\n",
    "#     content = node['page_content']\n",
    "#     print(content)\n",
    "#     content = re.sub(r'[^\\w\\s]', '', content)\n",
    "#     content = re.sub(r'\\s+', ' ', content)\n",
    "#     content = content.lower()\n",
    "#     # print(content)\n",
    "#     content = [c for c in content.split(' ') if c != '' and len(c) > 2]\n",
    "#     # print(content)\n",
    "#     for word in content:\n",
    "#         if word not in stop_words:\n",
    "#             if word not in postings_list:\n",
    "#                 postings_list[word] = [i]\n",
    "#             elif postings_list[word][-1] != i:\n",
    "#                 postings_list[word].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_sets(query_word, postings_list):\n",
    "    \"\"\"\n",
    "    Generates the root and base sets for the query word\n",
    "    \"\"\"\n",
    "    if query_word not in postings_list:\n",
    "        raise Exception('Word not in the postings list')\n",
    "    root_set = postings_list[query_word]\n",
    "    base_set = []\n",
    "    for node in root_set:\n",
    "        base_set.append(node)\n",
    "    # print(root_set)\n",
    "    root_set = set(root_set)\n",
    "    # print(root_set)\n",
    "    # print(base_set)\n",
    "    base_set = set(base_set)\n",
    "    # print(base_set)\n",
    "    # print(web_graph.edges)\n",
    "    for edge in web_graph.edges:\n",
    "        if edge[0] in root_set:\n",
    "            base_set.add(edge[1])\n",
    "        if edge[1] in root_set:\n",
    "            base_set.add(edge[0])\n",
    "    # print(base_set)\n",
    "    return root_set,base_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "def generate_adj_matrix(base_set):\n",
    "    adj = np.zeros((len(base_set), len(base_set)))\n",
    "    # print(adj)\n",
    "    bslist = list(base_set)\n",
    "    # print(bslist)\n",
    "    for edge in web_graph.edges:\n",
    "        if edge[0] in base_set and edge[1] in base_set:\n",
    "            # print(edge)\n",
    "            adj[bslist.index(edge[0])][bslist.index(edge[1])] = 1\n",
    "    # print(adj)\n",
    "    return adj\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "def generate_hub_authority_scores(adj_matrix):\n",
    "    aTa = np.dot(adj_matrix.T, adj_matrix)\n",
    "    aaT = np.dot(adj_matrix, adj_matrix.T)\n",
    "    print(len(adj_matrix))\n",
    "    v, V = np.linalg.eig(aaT.T)\n",
    "    left_vec = V[:, 0].T\n",
    "    left_vec = V[:, v.argmax()]\n",
    "    left_vec = left_vec / sum(left_vec)\n",
    "    h_vec = np.reshape(left_vec, (1, -1))\n",
    "    v, V = np.linalg.eig(aTa.T)\n",
    "    left_vec = V[:, 0].T\n",
    "    left_vec = V[:, v.argmax()]\n",
    "    left_vec = left_vec / sum(left_vec)\n",
    "    a_vec = np.reshape(left_vec, (1, -1))\n",
    "    # Return the principal left eigenvector\n",
    "    return a_vec, h_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "def generate_hub_authority_scores_power_iteration(adj_matrix):\n",
    "    aTa = np.dot(adj_matrix.T, adj_matrix)\n",
    "    aaT = np.dot(adj_matrix, adj_matrix.T)\n",
    "    a_vec = np.full((1, len(adj_matrix)), 1/len(adj_matrix))\n",
    "    h_vec = np.full((1, len(adj_matrix)), 1/len(adj_matrix))\n",
    "    for i in range(1000):\n",
    "        a_vec = np.dot(a_vec, aTa)\n",
    "        a_vec = a_vec / np.max(a_vec)\n",
    "        h_vec = np.dot(h_vec, aaT)\n",
    "        h_vec = h_vec / np.max(h_vec)\n",
    "    a_vec = a_vec/sum(a_vec[0])\n",
    "    h_vec = h_vec/sum(h_vec[0])\n",
    "    return a_vec, h_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "def main():\n",
    "    web_graph = nx.read_gpickle('web_graph.gpickle')\n",
    "    # Create a postings list\n",
    "    postings_list = {}\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # print(stop_words)\n",
    "    for i in range(len(web_graph.nodes)):\n",
    "        node = web_graph.nodes[i]\n",
    "        content = node['page_content']\n",
    "        # print(content)\n",
    "        content = re.sub(r'[^\\w\\s]', '', content)\n",
    "        content = re.sub(r'\\s+', ' ', content)\n",
    "        content = content.lower()\n",
    "        # print(content)\n",
    "        content = [c for c in content.split(' ') if c != '' and len(c) > 2]\n",
    "        # print(content)\n",
    "        for word in content:\n",
    "            if word not in stop_words:\n",
    "                if word not in postings_list:\n",
    "                    postings_list[word] = [i]\n",
    "                elif postings_list[word][-1] != i:\n",
    "                    postings_list[word].append(i)\n",
    "\n",
    "    query = input(\"Enter query word: \")\n",
    "    query = query.split()\n",
    "    query = query[0]\n",
    "    rs,bs = generate_sets(query, postings_list)\n",
    "    adjacency_list = generate_adj_matrix(bs)\n",
    "\n",
    "    authority, hub = generate_hub_authority_scores_power_iteration(adjacency_list)\n",
    "    base_set_list = list(bs)\n",
    "    scores = []\n",
    "    scores_auth = []\n",
    "    scores_hub = []\n",
    "    auth_sum = 0\n",
    "    hub_sum = 0\n",
    "    for i in range(len(authority[0])):\n",
    "        if authority[0][i] <= 0:\n",
    "            authority[0][i] = authority[0][i]*-1\n",
    "        if hub[0][i] < 0:\n",
    "            hub[0][i] = hub[0][i]*-1\n",
    "        scores.append([base_set_list[i],authority[0][i],hub[0][i]])\n",
    "        scores_auth.append([base_set_list[i],authority[0][i]])\n",
    "        scores_hub.append([base_set_list[i],hub[0][i]])\n",
    "        auth_sum = auth_sum+authority[0][i]\n",
    "        hub_sum = hub_sum+hub[0][i]\n",
    "\n",
    "    scores_auth = sorted(scores_auth, key=lambda x:x[1], reverse=True)\n",
    "    scores_auth = scores_auth[0:3]\n",
    "    scores_hub = sorted(scores_hub, key=lambda x:x[1],reverse=True)\n",
    "    scores_hub = scores_hub[0:3]\n",
    "\n",
    "    print(\"Top 3 authority scores are:\")\n",
    "    print(tabulate(scores_auth, headers = [\"Node\", \"Authority Score\"]))\n",
    "    print(\"\\nTop 3 Hub scores are:\")\n",
    "    print(tabulate(scores_hub, headers = [\"Node\", \"Hub Score\"]))\n",
    "\n",
    "    print(\"\\n List of all scores:\")\n",
    "    print(tabulate(scores, headers = [\"Node\", \"Authority Score\", \"Hub Score\"]))\n",
    "    print(\"Authority score sum = \"+str(auth_sum))\n",
    "    print(\"Hub score sum = \"+str(hub_sum))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 authority scores are:\n",
      "  Node    Authority Score\n",
      "------  -----------------\n",
      "     0           0.320012\n",
      "     3           0.21121\n",
      "    61           0.21121\n",
      "\n",
      "Top 3 Hub scores are:\n",
      "  Node    Hub Score\n",
      "------  -----------\n",
      "    10     0.320012\n",
      "    75     0.320012\n",
      "     0     0.204815\n",
      "\n",
      " List of all scores:\n",
      "  Node    Authority Score    Hub Score\n",
      "------  -----------------  -----------\n",
      "     0           0.320012     0.204815\n",
      "     3           0.21121      0\n",
      "    10          -0            0.320012\n",
      "    75           0.128785     0.320012\n",
      "    87           0.128785     0.155162\n",
      "    61           0.21121      0\n",
      "Authority score sum = 1.0\n",
      "Hub score sum = 1.0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69198bfb6d930cb083243c9ed831565bcd8bb8fc69eab5a2d003dfc0bdcfc55c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('IR-QRBol3kX')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}